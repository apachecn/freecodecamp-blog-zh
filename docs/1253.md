# å¦‚ä½•ç”¨ Rust å®ç°æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨

> åŸæ–‡ï¼š<https://www.freecodecamp.org/news/implement-naive-bayes-with-rust/>

æˆ‘æƒ³æé«˜æˆ‘çš„é”ˆæŠ€èƒ½ï¼Œä¹Ÿå¸®åŠ©ä½ ç£¨ç»ƒä½ çš„æŠ€èƒ½ã€‚æ‰€ä»¥æˆ‘å†³å®šå†™ä¸€ç³»åˆ—å…³äº Rust ç¼–ç¨‹è¯­è¨€çš„æ–‡ç« ã€‚

é€šè¿‡ç”¨é“é”ˆåˆ¶é€ ä¸œè¥¿ï¼Œæˆ‘ä»¬å°†åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­äº†è§£åˆ°å¹¿æ³›çš„æŠ€æœ¯æ¦‚å¿µã€‚åœ¨è¿™ä¸€æœŸä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ç”¨ Rust å®ç°æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°ä¸€äº›ä¸ç†Ÿæ‚‰çš„æœ¯è¯­æˆ–æ¦‚å¿µã€‚ä¸è¦æ°”é¦ã€‚å¦‚æœä½ æœ‰æ—¶é—´çš„è¯ï¼Œçœ‹çœ‹è¿™äº›ï¼Œä½†æ˜¯ä¸ç®¡æ€æ ·ï¼Œè¿™ç¯‡æ–‡ç« çš„ä¸»è¦æ€æƒ³ä¸ä¼šè®©ä½ è¿·å¤±ã€‚

## ä»€ä¹ˆæ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Ÿ

æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ˜¯ä¸€ç§åŸºäºè´å¶æ–¯å®šç†çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚[è´å¶æ–¯å®šç†](https://greenteapress.com/wp/think-bayes/)ç»™äº†æˆ‘ä»¬ä¸€ç§åœ¨ç»™å®šä¸€äº›æ•°æ®çš„æƒ…å†µä¸‹æ›´æ–°å‡è®¾(H)çš„æ¦‚ç‡çš„æ–¹æ³•ã€‚

ç”¨æ•°å­¦æ–¹æ³•è¡¨ç¤ºï¼Œæˆ‘ä»¬æœ‰:

\[P(H | D)= \ frac { P(D | H)P(H)} { P(D)} \]

å…¶ä¸­\(P(H|D) =\)ç»™å®š\(D\)çš„æ¦‚ç‡ã€‚

å¦‚æœæˆ‘ä»¬ç§¯ç´¯æ›´å¤šçš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç›¸åº”åœ°æ›´æ–°\(P(H|D)\)ã€‚

æœ´ç´ è´å¶æ–¯æ¨¡å‹åŸºäºä¸€ä¸ªå¤§çš„å‡è®¾:ä¸€ä¸ªæ•°æ®ç‚¹æ˜¯å¦å­˜åœ¨äºæ•°æ®é›†ä¸­ä¸è¯¥æ•°æ®é›†ä¸­å·²ç»å­˜åœ¨çš„æ•°æ®æ— å…³ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸€æ®µæ•°æ®ä¸ä¼ è¾¾ä»»ä½•å…¶ä»–æ•°æ®ç‚¹çš„ä¿¡æ¯ã€‚

æˆ‘ä»¬ä¸è®¤ä¸ºè¿™ç§å‡è®¾æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºå®ƒæ˜¯ç«™ä¸ä½è„šçš„ã€‚ä½†å®ƒä»ç„¶æ˜¯æœ‰ç”¨çš„ï¼Œå…è®¸æˆ‘ä»¬åˆ›å»ºå·¥ä½œå¾—ç›¸å½“å¥½çš„é«˜æ•ˆåˆ†ç±»å™¨( [source](https://probml.github.io/pml-book/book0.html) )ã€‚

æˆ‘ä»¬å°†æŠŠå¯¹æœ´ç´ è´å¶æ–¯çš„æè¿°ç•™åœ¨è¿™é‡Œã€‚è¿˜æœ‰æ›´å¤šçš„å¯ä»¥è¯´ï¼Œä½†è¿™ç¯‡æ–‡ç« çš„è¦ç‚¹æ˜¯å®è·µç”Ÿé”ˆã€‚

å¦‚æœæ‚¨æƒ³äº†è§£æœ‰å…³è¯¥ç®—æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¿™é‡Œæœ‰ä¸€äº›èµ„æº:

*   å¯¹äº Josh Starmer çš„è¿™æ®µè§†é¢‘ï¼Œæˆ‘è¯´ä¸å‡ºå¤šå°‘å¥½è¯ã€‚
*   Joel Grus åœ¨ä»–çš„å·¨è‘—*ä»å¤´å¼€å§‹çš„æ•°æ®ç§‘å­¦*ä¸­å†™äº†å…³äºæœ´ç´ è´å¶æ–¯çš„ä¸€ç« ï¼Œè¿™æ˜¯è¿™ä¸ªå®ç°çš„ä¸»è¦çµæ„Ÿã€‚
*   å¦‚æœæ•°å­¦ç¬¦å·æ˜¯ä½ çš„äº‹ï¼Œ[è¯•è¯•*ç»Ÿè®¡å­¦ä¹ çš„è¦ç´ *](https://hastie.su.domains/Papers/ESLII.pdf) çš„ 6.6.3 èŠ‚ã€‚
*   è¿™é‡Œæœ‰ä¸€ç¯‡å…³äºç®—æ³•å·¥ä½œåŸç†çš„æœ‰ç”¨æ–‡ç« ã€‚

æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„å…¸å‹åº”ç”¨æ˜¯åƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦å»ºé€ çš„ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°æ‰€æœ‰çš„ä»£ç :[https://github.com/josht-jpg/shaking-off-the-rust](https://github.com/josht-jpg/shaking-off-the-rust)

æˆ‘ä»¬å°†ä»åˆ›å»ºä¸€ä¸ªæ–°çš„è´§ç‰©åº“å¼€å§‹ã€‚

```
cargo new naive_bayes --lib
cd naive_bayes 
```

ç°åœ¨è®©æˆ‘ä»¬æ·±å…¥ç ”ç©¶ä¸€ä¸‹ã€‚

## é“é”ˆçš„ç¬¦å·åŒ–

æˆ‘ä»¬çš„åˆ†ç±»å™¨å°†æ¥æ”¶ä¸€æ¡æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›åƒåœ¾é‚®ä»¶æˆ–éåƒåœ¾é‚®ä»¶çš„åˆ†ç±»ã€‚

ä¸ºäº†å¤„ç†ç»™å®šçš„ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦*å¯¹å…¶è¿›è¡Œ*æ ‡è®°ã€‚æˆ‘ä»¬çš„æ ‡è®°åŒ–è¡¨ç¤ºå°†æ˜¯ä¸€ç»„å°å†™å•è¯ï¼Œå…¶ä¸­é¡ºåºå’Œé‡å¤æ¡ç›®è¢«å¿½ç•¥ã€‚æ‹‰æ–¯ç‰¹çš„ **`[std::collections::HashSet](https://doc.rust-lang.org/std/collections/struct.HashSet.html)`** ç»“æ„æ˜¯å®ç°è¿™ä¸€ç‚¹çš„ç»ä½³æ–¹å¼ã€‚

æˆ‘ä»¬å°†è¦ç¼–å†™çš„å‡½æ•°å°†è¦æ±‚ä½¿ç”¨ [regex](https://docs.rs/regex/latest/regex/) crateã€‚ç¡®ä¿åœ¨æ‚¨çš„`Cargo.toml`æ–‡ä»¶ä¸­åŒ…å«æ­¤ä¾èµ–å…³ç³»:

```
[dependencies]
regex = "^1.5.4" 
```

è¿™é‡Œæ˜¯`tokenize`å‡½æ•°:

```
// lib.rs

// We'll need HashMap later
use std::collections::{HashMap, HashSet};

extern crate regex;
use regex::Regex;

pub fn tokenize(lower_case_text: &str) -> HashSet<&str> {
    Regex::new(r"[a-z0-9']+")
        .unwrap()
        .find_iter(lower_case_text)
        .map(|mat| mat.as_str())
        .collect()
}
```

è¯¥å‡½æ•°ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰æ•°å­—å’Œå°å†™å­—æ¯ã€‚æ¯å½“æˆ‘ä»¬é‡åˆ°ä¸åŒç±»å‹çš„ç¬¦å·(é€šå¸¸æ˜¯ç©ºæ ¼æˆ–æ ‡ç‚¹ç¬¦å·)æ—¶ï¼Œæˆ‘ä»¬ä¼šæ‹†åˆ†è¾“å…¥ï¼Œå¹¶å°†è‡ªä¸Šæ¬¡æ‹†åˆ†ä»¥æ¥é‡åˆ°çš„æ‰€æœ‰æ•°å­—å’Œå­—æ¯ç»„åˆåœ¨ä¸€èµ·(æ‚¨å¯ä»¥[åœ¨ Rustã€‘ä¸­é˜…è¯»æœ‰å…³ regex çš„æ›´å¤šä¿¡æ¯)ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬åœ¨è¯†åˆ«å’Œéš”ç¦»è¾“å…¥æ–‡æœ¬ä¸­çš„å•è¯ã€‚](https://rust-lang-nursery.github.io/rust-cookbook/text/regex.html)

### ä¸€äº›ä¾¿åˆ©çš„ç»“æ„

ä½¿ç”¨ä¸€ä¸ª`struct`æ¥è¡¨ç¤ºä¸€ä¸ªæ¶ˆæ¯å°†ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚è¿™ä¸ª`struct`å°†åŒ…å«ä¸€ä¸ªç”¨äºæ¶ˆæ¯æ–‡æœ¬çš„*å­—ç¬¦ä¸²ç‰‡æ®µ*ï¼Œä»¥åŠä¸€ä¸ªå¸ƒå°”å€¼æ¥æŒ‡ç¤ºè¯¥æ¶ˆæ¯æ˜¯å¦æ˜¯åƒåœ¾é‚®ä»¶:

```
pub struct Message<'a> {
    pub text: &'a str,
    pub is_spam: bool,
}
```

`'a`æ˜¯ä¸€ä¸ªå¯¿å‘½å‚æ•°æ³¨é‡Šã€‚å¦‚æœä½ å¯¹ç”Ÿå‘½å‘¨æœŸä¸ç†Ÿæ‚‰ï¼Œå¹¶ä¸”æƒ³äº†è§£å®ƒä»¬ï¼Œæˆ‘æ¨èé˜…è¯» Rust ç¼–ç¨‹è¯­è¨€ä¹¦çš„[ç¬¬ 10.3 èŠ‚ã€‚](https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html)

ä¸€ä¸ª`struct`ä¹Ÿå¯ä»¥ç”¨æ¥è¡¨ç¤ºæˆ‘ä»¬çš„åˆ†ç±»å™¨ã€‚åœ¨åˆ›å»º`struct`ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç¨å¾®åç¦»ä¸€ä¸‹æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ã€‚

### ä»€ä¹ˆæ˜¯æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼Ÿ

å‡è®¾â€”â€”åœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¸­â€”â€”å•è¯ *fubar* å‡ºç°åœ¨ä¸€äº›éåƒåœ¾æ¶ˆæ¯ä¸­ï¼Œä½†æ²¡æœ‰å‡ºç°åœ¨ä»»ä½•åƒåœ¾æ¶ˆæ¯ä¸­ã€‚ç„¶åï¼Œæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨å°†ä¸ºä»»ä½•åŒ…å«å•è¯ *fubar* ( [source](https://www.youtube.com/watch?v=nt63k3bfXS0) )çš„é‚®ä»¶åˆ†é…ä¸€ä¸ªåƒåœ¾é‚®ä»¶æ¦‚ç‡ **0** ã€‚

é™¤éæˆ‘ä»¬è°ˆè®ºçš„æ˜¯æˆ‘åœ¨ç½‘ä¸Šçº¦ä¼šçš„æˆåŠŸï¼Œå¦åˆ™ä»…ä»…å› ä¸ºä¸€ä»¶äº‹è¿˜æ²¡æœ‰å‘ç”Ÿå°±ç»™å®ƒåˆ†é…ä¸€ä¸ª **0** çš„æ¦‚ç‡æ˜¯ä¸æ˜æ™ºçš„ã€‚

è¾“å…¥æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ã€‚è¿™æ˜¯å°†\(\alpha\)åŠ åˆ°æ¯ä¸ªä»¤ç‰Œçš„è§‚å¯Ÿæ¬¡æ•°ä¸Šçš„æŠ€æœ¯([æº](https://www.youtube.com/watch?v=nt63k3bfXS0))ã€‚è®©æˆ‘ä»¬ä»æ•°å­¦ä¸Šæ¥çœ‹:å¦‚æœæ²¡æœ‰æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼Œåœ¨åƒåœ¾é‚®ä»¶ä¸­çœ‹åˆ°å•è¯\(w\)çš„æ¦‚ç‡æ˜¯:

\[P(w | S)= \ frac { number \ of \ spam \ messages \ containing \ w } { total \ number \ of \ spam } \]

ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼Œå®ƒæ˜¯:

\[P(w | S)= \ frac {(a+number \ of \ spam \ messages \ containing \ w)} {(2a+total \ number \ of \ spam)} \]

å›åˆ°æˆ‘ä»¬çš„åˆ†ç±»å™¨`struct`:

```
pub struct NaiveBayesClassifier {
    pub alpha: f64,
    pub tokens: HashSet<String>,
    pub token_ham_counts: HashMap<String, i32>,
    pub token_spam_counts: HashMap<String, i32>,
    pub spam_messages_count: i32,
    pub ham_messages_count: i32,
} 
```

`NaiveBayesClassifier`çš„å®ç°æ¨¡å—å°†å›´ç»•ä¸€ä¸ª`train`æ–¹æ³•å’Œä¸€ä¸ª`predict`æ–¹æ³•ã€‚

## å¦‚ä½•è®­ç»ƒæˆ‘ä»¬çš„åˆ†ç±»å™¨

`train`æ–¹æ³•å°†æ¥æ”¶`Message`çš„ä¸€éƒ¨åˆ†ï¼Œå¹¶éå†æ¯ä¸ª`Message`ï¼Œæ‰§è¡Œä»¥ä¸‹æ“ä½œ:

*   æ£€æŸ¥è¯¥æ¶ˆæ¯æ˜¯å¦æ˜¯åƒåœ¾é‚®ä»¶ï¼Œå¹¶ç›¸åº”åœ°æ›´æ–°`spam_messages_count`æˆ–`ham_messages_count`ã€‚æˆ‘ä»¬å°†ä¸ºæ­¤åˆ›å»ºåŠ©æ‰‹å‡½æ•°`increment_message_classifications_count`ã€‚
*   ç”¨æˆ‘ä»¬çš„`tokenize`å‡½æ•°æ ‡è®°æ¶ˆæ¯çš„å†…å®¹ã€‚
*   éå†æ¶ˆæ¯ä¸­çš„æ¯ä¸ªä»¤ç‰Œï¼Œå¹¶:
*   å°†ä»¤ç‰Œæ’å…¥`tokens`åˆ°`HashSet`ï¼Œç„¶åæ›´æ–°`token_spam_counts`æˆ–`token_ham_counts`ã€‚æˆ‘ä»¬å°†ä¸ºæ­¤åˆ›å»ºåŠ©æ‰‹å‡½æ•°`increment_token_count`ã€‚

è¿™é‡Œæ˜¯æˆ‘ä»¬çš„`train`æ–¹æ³•çš„ä¼ªä»£ç ã€‚å¦‚æœä½ å–œæ¬¢ï¼Œåœ¨çœ‹æˆ‘ä¸‹é¢çš„å®ç°ä¹‹å‰ï¼Œè¯•ç€æŠŠä¼ªä»£ç è½¬æ¢æˆ Rustã€‚ä¸è¦çŠ¹è±«ï¼Œè¯·å°†æ‚¨çš„å®ç°å‘é€ç»™æˆ‘ï¼Œæˆ‘å¾ˆä¹æ„çœ‹åˆ°å®ƒï¼

```
implementation block for NaiveBayesClassifier {

	train(self, messages) {
		for each message in messages {
			self.increment_message_classifications_count(message)

			lowercase_text = to_lowercase(message.text)
			for each token in tokenize(lowercase_text) {
				self.tokens.insert(tokens)
				self.increment_token_count(token, message.is_spam)
			}			
		}
	}

	increment_message_classifications_count(self, message) {
		if message.is_spam {
			self.spam_messages_count = self.spam_messages_count + 1
		} else {
			self.ham_messages_count = self.ham_messages_count + 1
		}
	}

	increment_token_count(&mut self, token, is_spam) {
		if token is not a key of self.token_spam_counts {
			insert record with key=token and value=0 into self.token_spam_counts
		}

		if token is not a key of self.token_ham_counts {
			insert record with key=token and value=0 into self.token_ham_counts
		}

		if is_spam {
			self.token_spam_counts[token] = self.token_spam_counts[token] + 1
		} else {
			self.token_ham_counts[token] = self.token_ham_counts[token] + 1
		}
	}

} 
```

è¿™æ˜¯ Rust çš„å®ç°:

```
impl NaiveBayesClassifier {
    pub fn train(&mut self, messages: &[Message]) {
        for message in messages.iter() {
            self.increment_message_classifications_count(message);
            for token in tokenize(&message.text.to_lowercase()) {
                self.tokens.insert(token.to_string());
                self.increment_token_count(token, message.is_spam)
            }
        }
    }

    fn increment_message_classifications_count(&mut self, message: &Message) {
        if message.is_spam {
            self.spam_messages_count += 1;
        } else {
            self.ham_messages_count += 1;
        }
    }

    fn increment_token_count(&mut self, token: &str, is_spam: bool) {
        if !self.token_spam_counts.contains_key(token) {
            self.token_spam_counts.insert(token.to_string(), 0);
        }

        if !self.token_ham_counts.contains_key(token) {
            self.token_ham_counts.insert(token.to_string(), 0);
        }

        if is_spam {
            self.increment_spam_count(token);
        } else {
            self.increment_ham_count(token);
        }
    }

    fn increment_spam_count(&mut self, token: &str) {
        *self.token_spam_counts.get_mut(token).unwrap() += 1;
    }

    fn increment_ham_count(&mut self, token: &str) {
        *self.token_ham_counts.get_mut(token).unwrap() += 1;
    }
} 
```

æ³¨æ„åœ¨`HashMap`ä¸­å¢åŠ ä¸€ä¸ªå€¼æ˜¯éå¸¸éº»çƒ¦çš„ã€‚Rust ç¨‹åºå‘˜æ–°æ‰‹å¾ˆéš¾ç†è§£

`*self.token_spam_counts.get_mut(token).unwrap() += 1`

æ­£åœ¨åšã€‚

ä¸ºäº†ä½¿ä»£ç æ›´åŠ æ¸…æ™°ï¼Œæˆ‘åˆ›å»ºäº†`increment_spam_count`å’Œ`increment_ham_count`å‡½æ•°ã€‚ä½†æˆ‘å¯¹æ­¤å¹¶ä¸æ»¡æ„â€”â€”æ„Ÿè§‰è¿˜æ˜¯å¾ˆéº»çƒ¦ã€‚å¦‚æœæ‚¨æœ‰æ›´å¥½çš„æ–¹æ³•å»ºè®®ï¼Œè¯·è”ç³»æˆ‘ã€‚

## å¦‚ä½•ç”¨æˆ‘ä»¬çš„åˆ†ç±»å™¨è¿›è¡Œé¢„æµ‹

`predict`æ–¹æ³•å°†è·å–ä¸€ä¸ª*å­—ç¬¦ä¸²ç‰‡æ®µ*ï¼Œå¹¶è¿”å›æ¨¡å‹è®¡ç®—å‡ºçš„åƒåœ¾é‚®ä»¶æ¦‚ç‡ã€‚

æˆ‘ä»¬å°†åˆ›å»ºä¸¤ä¸ªåŠ©æ‰‹å‡½æ•°`probabilities_of_message`å’Œ`probabilites_of_token`æ¥ä¸º`predict`å®Œæˆç¹é‡çš„å·¥ä½œã€‚

`probabilities_of_message`è¿”å›\(P(Message|Spam)\)å’Œ\(P(Message|ham)\)ã€‚

`probabilities_of_token`è¿”å›\(P(Token|Spam)\)å’Œ\(P(Token|ham)\)ã€‚

è®¡ç®—è¾“å…¥æ¶ˆæ¯æ˜¯åƒåœ¾æ¶ˆæ¯çš„æ¦‚ç‡åŒ…æ‹¬å°†æ¯ä¸ªå•è¯åœ¨åƒåœ¾æ¶ˆæ¯ä¸­å‡ºç°çš„æ¦‚ç‡ç›¸ä¹˜ã€‚

ç”±äºæ¦‚ç‡æ˜¯ä»‹äº 0 å’Œ 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œå°†è®¸å¤šæ¦‚ç‡ç›¸ä¹˜ä¼šå¯¼è‡´**ä¸‹æº¢** ( [æº](https://learning.oreilly.com/library/view/data-science-from/9781492041122/))ã€‚è¿™æ˜¯å½“ä¸€ä¸ªæ“ä½œäº§ç”Ÿçš„æ•°å­—å°äºè®¡ç®—æœºèƒ½å¤Ÿå‡†ç¡®å­˜å‚¨çš„æ•°å­—æ—¶(è¿™é‡Œçš„[è§](https://www.techopedia.com/definition/712/underflow)å’Œ[è§](https://www.amazon.ca/Numerical-Analysis-Richard-Burden/dp/1305253663/ref=asc_df_1305253663/?tag=googleshopc0c-20&linkCode=df0&hvadid=293014842916&hvpos=&hvnetw=g&hvrand=9862733826869340686&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9001551&hvtargid=pla-450666638521&psc=1))ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¯¹æ•°å’ŒæŒ‡æ•°å°†ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ç³»åˆ—åŠ æ³•:

\[\prod_{i=0}^{n}p_i = exp(\sum_{i=0}^{n}æ—¥å¿—(p_i)) \]

è¿™æ˜¯å› ä¸ºå¯¹äºä»»ä½•å®æ•°\(a\)å’Œ\(b\ ),

\[ab = exp(log(ab))= exp(log(a)+log(b))\]

æˆ‘å°†å†æ¬¡ä» predict æ–¹æ³•çš„ä¼ªä»£ç å¼€å§‹:

```
implementation block for NaiveBayesCalssifier {
	/*...*/

	predict(self, text) {
		lower_case_text = to_lowercase(text)
		message_tokens = tokenize(text)
		(prob_if_spam, prob_if_ham) = self.probabilities_of_message(message_tokens)
		return prob_if_spam / (prob_if_spam + prob_if_ham)
	}

	probabilities_of_message(self, message_tokens) {
		log_prob_if_spam = 0
		log_prob_if_ham = 0

		for each token in self.tokens {
			(prob_if_spam, prob_if_ham) = self.probabilites_of_token(token)

			if message_tokens contains token {
				log_prob_if_spam = log_prob_if_spam + ln(prob_if_spam)
				log_prob_if_ham = log_prob_if_ham + ln(prob_if_ham)
			} else {
				log_prob_if_spam = log_prob_if_spam + ln(1 - prob_if_spam)
				log_prob_if_ham = log_prob_if_ham + ln(1 - prob_if_ham)
			}
		}

		prob_if_spam = exp(log_prob_if_spam)
		prob_if_ham = exp(log_prob_if_ham)

		return (prob_if_spam, prob_if_ham)
	}

	probabilites_of_token(self, token) {
		prob_of_token_spam = (self.token_spam_counts[token] + self.alpha) 
						/ (self.spam_messages_count + 2 * self.alpha)

		prob_of_token_ham = (self.token_ham_counts[token] + self.alpha) 
						/ (self.ham_messages_count + 2 * self.alpha)

		return (prob_of_token_spam, prob_of_token_ham)
	}

} 
```

è¿™æ˜¯ Rust ä»£ç :

```
impl NaiveBayesClassifier {

		/*...*/

	pub fn predict(&self, text: &str) -> f64 {
        let lower_case_text = text.to_lowercase();
        let message_tokens = tokenize(&lower_case_text);
        let (prob_if_spam, prob_if_ham) = self.probabilities_of_message(message_tokens);

        return prob_if_spam / (prob_if_spam + prob_if_ham);
    }

    fn probabilities_of_message(&self, message_tokens: HashSet<&str>) -> (f64, f64) {
        let mut log_prob_if_spam = 0.;
        let mut log_prob_if_ham = 0.;

        for token in self.tokens.iter() {
            let (prob_if_spam, prob_if_ham) = self.probabilites_of_token(&token);

            if message_tokens.contains(token.as_str()) {
                log_prob_if_spam += prob_if_spam.ln();
                log_prob_if_ham += prob_if_ham.ln();
            } else {
                log_prob_if_spam += (1\. - prob_if_spam).ln();
                log_prob_if_ham += (1\. - prob_if_ham).ln();
            }
        }

        let prob_if_spam = log_prob_if_spam.exp();
        let prob_if_ham = log_prob_if_ham.exp();

        return (prob_if_spam, prob_if_ham);
    }

    fn probabilites_of_token(&self, token: &str) -> (f64, f64) {
        let prob_of_token_spam = (self.token_spam_counts[token] as f64 + self.alpha)
            / (self.spam_messages_count as f64 + 2\. * self.alpha);

        let prob_of_token_ham = (self.token_ham_counts[token] as f64 + self.alpha)
            / (self.ham_messages_count as f64 + 2\. * self.alpha);

        return (prob_of_token_spam, prob_of_token_ham);
    }
} 
```

## å¦‚ä½•æµ‹è¯•æˆ‘ä»¬çš„åˆ†ç±»å™¨

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä¸‹é¢çš„æµ‹è¯•æ‰‹åŠ¨é€šè¿‡æœ´ç´ è´å¶æ–¯ï¼Œç„¶åæ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹ç»™å‡ºç›¸åŒçš„ç»“æœã€‚

æ‚¨å¯èƒ½ä¼šå‘ç°æµè§ˆæµ‹è¯•çš„é€»è¾‘æ˜¯å€¼å¾—çš„ï¼Œæˆ–è€…æ‚¨å¯èƒ½åªæƒ³å°†ä»£ç ç²˜è´´åˆ° lib.rs æ–‡ä»¶çš„åº•éƒ¨ï¼Œä»¥æ£€æŸ¥æ‚¨çš„ä»£ç æ˜¯å¦å·¥ä½œã€‚

```
// ...lib.rs

pub fn new_classifier(alpha: f64) -> NaiveBayesClassifier {
    return NaiveBayesClassifier {
        alpha,
        tokens: HashSet::new(),
        token_ham_counts: HashMap::new(),
        token_spam_counts: HashMap::new(),
        spam_messages_count: 0,
        ham_messages_count: 0,
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn naive_bayes() {
        let train_messages = [
            Message {
                text: "Free Bitcoin viagra XXX christmas deals ğŸ˜»ğŸ˜»ğŸ˜»",
                is_spam: true,
            },
            Message {
                text: "My dear Granddaughter, please explain Bitcoin over Christmas dinner",
                is_spam: false,
            },
            Message {
                text: "Here in my garage...",
                is_spam: true,
            },
        ];

        let alpha = 1.;
        let num_spam_messages = 2.;
        let num_ham_messages = 1.;

        let mut model = new_classifier(alpha);
        model.train(&train_messages);

        let mut expected_tokens: HashSet<String> = HashSet::new();
        for message in train_messages.iter() {
            for token in tokenize(&message.text.to_lowercase()) {
                expected_tokens.insert(token.to_string());
            }
        }

        let input_text = "Bitcoin crypto academy Christmas deals";

        let probs_if_spam = [
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "Free"  (not present)
            (1\. + alpha) / (num_spam_messages + 2\. * alpha),      // "Bitcoin"  (present)
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "viagra"  (not present)
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "XXX"  (not present)
            (1\. + alpha) / (num_spam_messages + 2\. * alpha),      // "christmas"  (present)
            (1\. + alpha) / (num_spam_messages + 2\. * alpha),      // "deals"  (present)
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "my"  (not present)
            1\. - (0\. + alpha) / (num_spam_messages + 2\. * alpha), // "dear"  (not present)
            1\. - (0\. + alpha) / (num_spam_messages + 2\. * alpha), // "granddaughter"  (not present)
            1\. - (0\. + alpha) / (num_spam_messages + 2\. * alpha), // "please"  (not present)
            1\. - (0\. + alpha) / (num_spam_messages + 2\. * alpha), // "explain"  (not present)
            1\. - (0\. + alpha) / (num_spam_messages + 2\. * alpha), // "over"  (not present)
            1\. - (0\. + alpha) / (num_spam_messages + 2\. * alpha), // "dinner"  (not present)
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "here"  (not present)
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "in"  (not present)
            1\. - (1\. + alpha) / (num_spam_messages + 2\. * alpha), // "garage"  (not present)
        ];

        let probs_if_ham = [
            1\. - (0\. + alpha) / (num_ham_messages + 2\. * alpha), // "Free"  (not present)
            (1\. + alpha) / (num_ham_messages + 2\. * alpha),      // "Bitcoin"  (present)
            1\. - (0\. + alpha) / (num_ham_messages + 2\. * alpha), // "viagra"  (not present)
            1\. - (0\. + alpha) / (num_ham_messages + 2\. * alpha), // "XXX"  (not present)
            (1\. + alpha) / (num_ham_messages + 2\. * alpha),      // "christmas"  (present)
            (0\. + alpha) / (num_ham_messages + 2\. * alpha),      // "deals"  (present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "my"  (not present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "dear"  (not present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "granddaughter"  (not present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "please"  (not present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "explain"  (not present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "over"  (not present)
            1\. - (1\. + alpha) / (num_ham_messages + 2\. * alpha), // "dinner"  (not present)
            1\. - (0\. + alpha) / (num_ham_messages + 2\. * alpha), // "here"  (not present)
            1\. - (0\. + alpha) / (num_ham_messages + 2\. * alpha), // "in"  (not present)
            1\. - (0\. + alpha) / (num_ham_messages + 2\. * alpha), // "garage"  (not present)
        ];

        let p_if_spam_log: f64 = probs_if_spam.iter().map(|p| p.ln()).sum();
        let p_if_spam = p_if_spam_log.exp();

        let p_if_ham_log: f64 = probs_if_ham.iter().map(|p| p.ln()).sum();
        let p_if_ham = p_if_ham_log.exp();

        // P(message | spam) / (P(messge | spam) + P(message | ham)) rounds to 0.97
        assert!((model.predict(input_text) - p_if_spam / (p_if_spam + p_if_ham)).abs() < 0.000001);
    }
}
```

ç°åœ¨è¿è¡Œ`cargo test`ã€‚å¦‚æœæ‚¨è®¤ä¸ºè¿™æ˜¯æ­£ç¡®çš„ï¼Œé‚£ä¹ˆåšå¾—å¥½ï¼Œæ‚¨å·²ç»åœ¨ Rust ä¸­å®ç°äº†ä¸€ä¸ªæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼

è°¢è°¢ä½ å’Œæˆ‘ä¸€èµ·ç¼–ç ï¼Œæœ‹å‹ä»¬ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚

### å‚è€ƒ

1.  Grusï¼ŒJ. (2019 å¹´)ã€‚*æ•°æ®ç§‘å­¦ä»é›¶å¼€å§‹:Python çš„åŸºæœ¬åŸç†ï¼Œç¬¬äºŒç‰ˆã€‚*å¥¥è±åˆ©åª’ä½“ã€‚
2.  å”å°¼(2021)ã€‚*æ€è€ƒè´å¶æ–¯:Python ä¸­çš„è´å¶æ–¯ç»Ÿè®¡ï¼Œç¬¬äºŒç‰ˆã€‚*å¥¥è±åˆ©åª’ä½“ã€‚
3.  å¢¨è²ï¼ŒK. (2012 å¹´)ã€‚*æœºå™¨å­¦ä¹ :æ¦‚ç‡è§†è§’ã€‚*éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚
4.  Dhinakaranï¼ŒV. (2017)ã€‚*é“é”ˆé£Ÿè°±ã€‚* Packtã€‚
5.  [Ngï¼ŒA. (2018)ã€‚æ–¯å¦ç¦ CS229:ç¬¬äº”è®²- GDA &æœ´ç´ è´å¶æ–¯ã€‚](https://www.youtube.com/watch?v=nt63k3bfXS0)
6.  Burdenï¼ŒR. Fairesï¼ŒJ. Burdenï¼ŒA. (2015 å¹´)ã€‚*æ•°å€¼åˆ†æï¼Œç¬¬ 10 ç‰ˆã€‚*å¸ƒé²å…‹æ–¯ç§‘å°”ã€‚
7.  [*ä¸‹æº¢ã€‚*ç§‘æŠ€ç™¾ç§‘ã€‚](https://www.techopedia.com/definition/712/underflow)