# å¦‚ä½•ç”¨è‹¹æœçš„ CoreML å’Œ Vision APIs æ­å»ºå›¾åƒè¯†åˆ« iOS app

> åŸæ–‡ï¼š<https://www.freecodecamp.org/news/ios-coreml-vision-image-recognition-3619cf319d0b/>

é©¬å…‹Â·æ›¼è‹å°”

# å¦‚ä½•ç”¨è‹¹æœçš„ CoreML å’Œ Vision APIs æ­å»ºå›¾åƒè¯†åˆ« iOS app

![1*vm51CWzLgOE2mTHwWdQENw](img/19802a33c5456ce5e9b92cba5dae6636.png)

éšç€ä»Šå¹´è‹¹æœå…¨çƒå¼€å‘è€…å¤§ä¼šä¸Š [CoreML](https://developer.apple.com/documentation/coreml) å’Œ new Vision APIs çš„å‘å¸ƒï¼Œæœºå™¨å­¦ä¹ ä»æœªå¦‚æ­¤å®¹æ˜“è¿›å…¥ã€‚ä»Šå¤©æˆ‘å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ªç®€å•çš„å›¾åƒè¯†åˆ«åº”ç”¨ç¨‹åºã€‚

æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•è®¿é—® iPhone çš„æ‘„åƒå¤´ï¼Œä»¥åŠå¦‚ä½•å°†æ‘„åƒå¤´çœ‹åˆ°çš„å†…å®¹ä¼ é€’ç»™æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œåˆ†æã€‚æˆ‘ä»¬å°†ä»¥ç¼–ç¨‹çš„æ–¹å¼å®Œæˆè¿™ä¸€åˆ‡ï¼Œä¸ä½¿ç”¨æ•…äº‹æ¿ï¼æˆ‘çŸ¥é“è¿™å¾ˆç–¯ç‹‚ã€‚

ä¸‹é¢æ˜¯æˆ‘ä»¬ä»Šå¤©è¦å®Œæˆçš„ä»»åŠ¡:

```
//
//  ViewController.swift
//  cameraTest
//
//  Created by Mark Mansur on 2017-08-01.
//  Copyright Â© 2017 Mark Mansur. All rights reserved.
//
import UIKit
import AVFoundation
import Vision

class ViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate {
    let label: UILabel = {
        let label = UILabel()
        label.textColor = .white
        label.translatesAutoresizingMaskIntoConstraints = false
        label.text = "Label"
        label.font = label.font.withSize(30)
        return label
    }()

    override func viewDidLoad() {
        super.viewDidLoad()

        setupCaptureSession()

        view.addSubview(label)
        setupLabel()
    }

    func setupCaptureSession() {
        let captureSession = AVCaptureSession()

        // search for available capture devices
        let availableDevices = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInWideAngleCamera], mediaType: AVMediaType.video, position: .back).devices

        // setup capture device, add input to our capture session
        do {
            if let captureDevice = availableDevices.first {
                let captureDeviceInput = try AVCaptureDeviceInput(device: captureDevice)
                captureSession.addInput(captureDeviceInput)
            }
        } catch {
            print(error.localizedDescription)
        }

        // setup output, add output to our capture session
        let captureOutput = AVCaptureVideoDataOutput()
        captureOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "videoQueue"))
        captureSession.addOutput(captureOutput)

        let previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
        previewLayer.frame = view.frame
        view.layer.addSublayer(previewLayer)

        captureSession.startRunning()
    }

    // called everytime a frame is captured
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard let model = try? VNCoreMLModel(for: Resnet50().model) else {return}

        let request = VNCoreMLRequest(model: model) { (finishedRequest, error) in

            guard let results = finishedRequest.results as? [VNClassificationObservation] else { return }
            guard let Observation = results.first else { return }

            DispatchQueue.main.async(execute: {
                self.label.text = "\(Observation.identifier)"
            })
        }
        guard let pixelBuffer: CVPixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

        // executes request
        try? VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:]).perform([request])
    }

    func setupLabel() {
        label.centerXAnchor.constraint(equalTo: view.centerXAnchor).isActive = true
        label.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -50).isActive = true
    }
}
```

ViewController.swift

### ğŸ™ŒğŸ»æ­¥éª¤ 1:åˆ›å»ºä¸€ä¸ªæ–°é¡¹ç›®ã€‚

å¯åŠ¨ Xcode å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„å•è§†å›¾åº”ç”¨ç¨‹åºã€‚ç»™å®ƒä¸€ä¸ªåå­—ï¼Œä¹Ÿè®¸æ˜¯â€œå›¾åƒè¯†åˆ«â€é€‰æ‹© swift ä½œä¸ºä¸»è¦è¯­è¨€å¹¶ä¿å­˜æ‚¨çš„æ–°é¡¹ç›®ã€‚

### ğŸ‘‹ç¬¬äºŒæ­¥:å‘Šåˆ«æ•…äº‹æ¿ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥ç¼–ç¨‹çš„æ–¹å¼åšæ‰€æœ‰äº‹æƒ…ï¼Œä¸éœ€è¦æ•…äº‹æ¿ã€‚ä¹Ÿè®¸æˆ‘ä¼šåœ¨å¦ä¸€ç¯‡æ–‡ç« ä¸­è§£é‡Šä¸ºä»€ä¹ˆã€‚

åˆ é™¤`main.storyboard`ã€‚

å¯¼èˆªè‡³`info.plist` å¹¶å‘ä¸‹æ»šåŠ¨è‡³éƒ¨ç½²ä¿¡æ¯ã€‚æˆ‘ä»¬éœ€è¦å‘Šè¯‰ Xcode æˆ‘ä»¬ä¸å†ä½¿ç”¨æ•…äº‹æ¿äº†ã€‚

åˆ é™¤ä¸»ç•Œé¢ã€‚

![1*W-p1_py_aMgNrnBh4ljJOg](img/fe567cf76408629504ae66f3ae001505.png)

æ²¡æœ‰æ•…äº‹æ¿ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åˆ›å»ºåº”ç”¨ç¨‹åºçª—å£å’Œæ ¹è§†å›¾æ§åˆ¶å™¨ã€‚

å°†ä»¥ä¸‹å†…å®¹æ·»åŠ åˆ°`AppDelegate.swift`ä¸­çš„`application()`åŠŸèƒ½:

```
 func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -> Bool {
        // Override point for customization after application launch.

        window = UIWindow()
        window?.makeKeyAndVisible()
        let vc = ViewController()

        window?.rootViewController = vc
        return true
    }
```

AppDelegate.swift

æˆ‘ä»¬ç”¨`UIWindow()`ã€**ã€**æ‰‹åŠ¨åˆ›å»º app çª—å£ï¼Œåˆ›å»ºæˆ‘ä»¬çš„è§†å›¾æ§åˆ¶å™¨ï¼Œå¹¶å‘Šè¯‰çª—å£ä½¿ç”¨å®ƒä½œä¸ºå®ƒçš„æ ¹è§†å›¾æ§åˆ¶å™¨ã€‚

åº”ç”¨ç¨‹åºç°åœ¨åº”è¯¥å¯ä»¥åœ¨æ²¡æœ‰æ•…äº‹æ¿çš„æƒ…å†µä¸‹æ„å»ºå’Œè¿è¡Œäº†ğŸ˜

### âš™ï¸æ­¥éª¤ 3:è®¾ç½® AVCaptureSessionã€‚

åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œå¯¼å…¥ UIKitã€AVFoundation å’Œ Visionã€‚AVCaptureSession å¯¹è±¡å¤„ç†æ•è·æ´»åŠ¨ï¼Œå¹¶ç®¡ç†è¾“å…¥è®¾å¤‡(å¦‚åç½®æ‘„åƒå¤´)å’Œè¾“å‡ºä¹‹é—´çš„æ•°æ®æµã€‚

æˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®¾ç½®æˆ‘ä»¬çš„æ•è·ä¼šè¯ã€‚

åœ¨`ViewController.swift` ä¸­åˆ›å»º`setupCaptureSession()`ï¼Œå¹¶å®ä¾‹åŒ–ä¸€ä¸ªæ–°çš„`AVCaptureSession`ã€‚

```
func setupCaptureSession() {

        // creates a new capture session
        let captureSession = AVCaptureSession()
}
```

ViewController.swift

ä¸è¦å¿˜è®°ä»`ViewDidLoad()`è°ƒç”¨è¿™ä¸ªæ–°å‡½æ•°ã€‚

```
override func viewDidLoad() {
        super.viewDidLoad()

        setupCaptureSession()
}
```

ViewController.swift

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåè§†æ‘„åƒå¤´çš„å‚ç…§ç‰©ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`DiscoverySession` æ¥æ ¹æ®æˆ‘ä»¬çš„æœç´¢æ ‡å‡†æŸ¥è¯¢å¯ç”¨çš„æ•è·è®¾å¤‡ã€‚

æ·»åŠ ä»¥ä¸‹ä»£ç :

```
// search for available capture devices
let availableDevices = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInWideAngleCamera], mediaType: AVMediaType.video, position: .back).devices 
```

ViewController.swift

`AvailableDevices` ç°åœ¨åŒ…å«ç¬¦åˆæˆ‘ä»¬æœç´¢æ ‡å‡†çš„å¯ç”¨è®¾å¤‡åˆ—è¡¨ã€‚

æˆ‘ä»¬ç°åœ¨éœ€è¦è®¿é—®æˆ‘ä»¬çš„`captureDevice`ï¼Œå¹¶å°†å…¶ä½œä¸ºè¾“å…¥æ·»åŠ åˆ°æˆ‘ä»¬çš„`captureSession`ã€‚

å‘æ•è·ä¼šè¯æ·»åŠ è¾“å…¥ã€‚

```
// get capture device, add device input to capture session
do {
    if let captureDevice = availableDevices.first {
        captureSession.addInput(try AVCaptureDeviceInput(device: captureDevice))
    }
} catch {
    print(error.localizedDescription)
}
```

ViewController.swift

ç¬¬ä¸€ä¸ªå¯ç”¨çš„è®¾å¤‡å°†æ˜¯åç½®æ‘„åƒå¤´ã€‚æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„æ•è·è®¾å¤‡åˆ›å»ºä¸€ä¸ªæ–°çš„`AVCaptureDeviceInput` ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æ•è·ä¼šè¯ä¸­ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†è¾“å…¥è®¾ç½®ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®¨è®ºå¦‚ä½•è¾“å‡ºæ‘„åƒæœºæ•æ‰åˆ°çš„å†…å®¹ã€‚

å‘æˆ‘ä»¬çš„æ•è·ä¼šè¯æ·»åŠ è§†é¢‘è¾“å‡ºã€‚

```
// setup output, add output to our capture session
let captureOutput = AVCaptureVideoDataOutput()
captureSession.addOutput(captureOutput)
```

ViewController.swift

`AVCaptureVideoDataOutput`æ˜¯æ•è·è§†é¢‘çš„è¾“å‡ºã€‚å®ƒè¿˜ä¸ºæˆ‘ä»¬æä¾›äº†å¯¹è¢«æ•è·çš„å¸§çš„è®¿é—®ï¼Œä»¥ä¾¿ç”¨æˆ‘ä»¬ç¨åå°†çœ‹åˆ°çš„å§”æ‰˜æ–¹æ³•è¿›è¡Œå¤„ç†ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•è·ä¼šè¯çš„è¾“å‡ºä½œä¸ºå­å±‚æ·»åŠ åˆ°æˆ‘ä»¬çš„è§†å›¾ä¸­ã€‚

å°†æ•è·ä¼šè¯è¾“å‡ºä½œä¸ºå­å±‚æ·»åŠ åˆ°è§†å›¾æ§åˆ¶å™¨çš„è§†å›¾ä¸­ã€‚

```
let previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
previewLayer.frame = view.frame
view.layer.addSublayer(previewLayer)

captureSession.startRunning()
```

ViewController.swift

æˆ‘ä»¬åŸºäºæ•è·ä¼šè¯åˆ›å»ºä¸€ä¸ªå±‚ï¼Œå¹¶å°†è¯¥å±‚ä½œä¸ºå­å±‚æ·»åŠ åˆ°è§†å›¾ä¸­ã€‚`CaptureSession.startRunning()`å¼€å§‹æˆ‘ä»¬ä¹‹å‰è¿æ¥çš„ä»è¾“å…¥åˆ°è¾“å‡ºçš„æµç¨‹ã€‚

### ğŸ“·ç¬¬å››æ­¥:å…è®¸ä½¿ç”¨ç›¸æœºï¼Ÿå‡†è®¸ã€‚

å‡ ä¹æ¯ä¸ªäººéƒ½æ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€åº”ç”¨ç¨‹åºï¼Œå¹¶è¢«æç¤ºå…è®¸åº”ç”¨ç¨‹åºä½¿ç”¨ç›¸æœºã€‚ä» iOS 10 å¼€å§‹ï¼Œå¦‚æœæˆ‘ä»¬åœ¨å°è¯•è®¿é—®ç›¸æœºä¹‹å‰ä¸æç¤ºç”¨æˆ·ï¼Œæˆ‘ä»¬çš„åº”ç”¨ç¨‹åºå°†ä¼šå´©æºƒã€‚

å¯¼èˆªåˆ°`info.plist` å¹¶æ·»åŠ ä¸€ä¸ªåä¸º`NSCameraUsageDescription`çš„æ–°é”®ã€‚åœ¨â€œå€¼â€æ ä¸­ï¼Œç®€å•åœ°å‘ç”¨æˆ·è§£é‡Šä¸ºä»€ä¹ˆä½ çš„åº”ç”¨ç¨‹åºéœ€è¦æ‘„åƒå¤´è®¿é—®ã€‚

ç°åœ¨ï¼Œå½“ç”¨æˆ·ç¬¬ä¸€æ¬¡å¯åŠ¨åº”ç”¨ç¨‹åºæ—¶ï¼Œä»–ä»¬ä¼šè¢«æç¤ºå…è®¸è®¿é—®ç›¸æœºã€‚

### ğŸ“Šç¬¬äº”æ­¥:è·å–æ¨¡å‹ã€‚

è¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒå¾ˆå¯èƒ½æ˜¯æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¿…é¡»èƒ½å¤Ÿæ¥å—ä¸€ä¸ªå›¾åƒï¼Œå¹¶ç»™æˆ‘ä»¬ä¸€ä¸ªå›¾åƒæ˜¯ä»€ä¹ˆçš„é¢„æµ‹ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°å…è´¹è®­ç»ƒçš„æ¨¡ç‰¹ã€‚æˆ‘é€‰çš„æ˜¯ ResNet50ã€‚

è·å¾—æ¨¡å‹åï¼Œå°†å…¶æ‹–æ”¾åˆ° Xcode ä¸­ã€‚å®ƒå°†è‡ªåŠ¨ç”Ÿæˆå¿…è¦çš„ç±»ï¼Œä¸ºæ‚¨æä¾›ä¸€ä¸ªä¸æ¨¡å‹äº¤äº’çš„æ¥å£ã€‚

### ğŸç¬¬å…­æ­¥:å›¾åƒåˆ†æã€‚

ä¸ºäº†åˆ†ææ‘„åƒæœºçœ‹åˆ°äº†ä»€ä¹ˆï¼Œæˆ‘ä»¬éœ€è¦ä»¥æŸç§æ–¹å¼è®¿é—®æ‘„åƒæœºæ•æ‰åˆ°çš„å¸§ã€‚

ç¬¦åˆ`AVCaptureVideoDataOutputSampleBufferDelegate` ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç•Œé¢ï¼Œæ¯å½“ç›¸æœºæ•æ‰åˆ°ä¸€å¸§å›¾åƒæ—¶ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥ä¸ä¹‹äº¤äº’å¹¶å¾—åˆ°é€šçŸ¥ã€‚

ä½¿`ViewController`ä¸`AVCaptureVideoDataOutputSampleBufferDelegate`ä¸€è‡´ã€‚

æˆ‘ä»¬éœ€è¦å‘Šè¯‰æˆ‘ä»¬çš„è§†é¢‘è¾“å‡ºï¼ŒViewController æ˜¯å®ƒçš„æ ·æœ¬ç¼“å†²å§”æ‰˜ã€‚

åœ¨`SetupCaptureSession()`ä¸­å¢åŠ ä»¥ä¸‹ä¸€è¡Œ:

```
captureOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "videoQueue")) 
```

ViewController.swift

æ·»åŠ ä»¥ä¸‹åŠŸèƒ½:

```
func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard let model = try? VNCoreMLModel(for: Resnet50().model) else { return }
        let request = VNCoreMLRequest(model: model) { (finishedRequest, error) in
            guard let results = finishedRequest.results as? [VNClassificationObservation] else { return }
            guard let Observation = results.first else { return }

            DispatchQueue.main.async(execute: {
                self.label.text = "\(Observation.identifier)"
            })
        }
        guard let pixelBuffer: CVPixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

        // executes request
        try? VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:]).perform([request])
    }
```

ViewController.swift

æ¯æ¬¡æ•æ‰åˆ°ä¸€å¸§ï¼Œé€šè¿‡è°ƒç”¨`captureOutput()`é€šçŸ¥ä»£ç†ã€‚è¿™æ˜¯ä¸€ä¸ªç”¨ CoreML è¿›è¡Œå›¾åƒåˆ†æçš„å®Œç¾åœ°æ–¹ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`VNCoreMLModel` ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªä¸ vision æ¡†æ¶ä¸€èµ·ä½¿ç”¨çš„ CoreML æ¨¡å‹ã€‚æˆ‘ä»¬ç”¨ Resnet50 æ¨¡å‹åˆ›å»ºå®ƒã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºæˆ‘ä»¬çš„æ„¿æ™¯è¯·æ±‚ã€‚åœ¨å®Œæˆå¤„ç†ç¨‹åºä¸­ï¼Œæˆ‘ä»¬ç”¨æ¨¡å‹è¿”å›çš„æ ‡è¯†ç¬¦æ›´æ–°å±å¹•ä¸Šçš„ UILabelã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä¼ é€’ç»™æˆ‘ä»¬çš„å¸§ä»`CMSampleBuffer`è½¬æ¢ä¸º`CVPixelBuffer`ã€‚è¿™æ˜¯æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œåˆ†ææ‰€éœ€çš„æ ¼å¼ã€‚

æœ€åï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ª`VNImageRequestHandler`æ¥æ‰§è¡Œè§†è§‰è¯·æ±‚ã€‚

### ğŸ—’ç¬¬ä¸ƒæ­¥:åˆ›å»ºä¸€ä¸ªæ ‡ç­¾ã€‚

æœ€åä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ªåŒ…å«æ¨¡å‹é¢„æµ‹çš„`UILabel`ã€‚

åˆ›å»ºä¸€ä¸ªæ–°çš„`UILabel` ï¼Œå¹¶ä½¿ç”¨çº¦æŸå¯¹å…¶è¿›è¡Œå®šä½ã€‚

```
let label: UILabel = {
        let label = UILabel()
        label.textColor = .white
        label.translatesAutoresizingMaskIntoConstraints = false
        label.text = "Label"
        label.font = label.font.withSize(30)
        return label
    }()

func setupLabel() {
        label.centerXAnchor.constraint(equalTo: view.centerXAnchor).isActive = true
        label.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -50).isActive = true
}
```

ViewController.swift

ä¸è¦å¿˜è®°æ·»åŠ æ ‡ç­¾ä½œä¸ºå­è§†å›¾ï¼Œå¹¶ä»`ViewDidLoad()`ä¸­è°ƒç”¨`setupLabel()`ã€‚

```
view.addSubview(label)
setupLabel()
```

ViewController.swift

ä½ å¯ä»¥ä» [GitHub è¿™é‡Œ](https://github.com/markmansur/CoreML-Vision-demo)ä¸‹è½½å®Œæˆçš„é¡¹ç›®ã€‚

å–œæ¬¢ä½ çœ‹åˆ°çš„å—ï¼Ÿç»™è¿™ç¯‡æ–‡ç« ç‚¹ä¸ªå¤§æ‹‡æŒ‡ğŸ‘ï¼Œåœ¨ [Twitter](https://twitter.com/MarkMansur2) ã€ [GitHub](https://github.com/markmansur) ä¸Šå…³æ³¨æˆ‘ï¼Œæˆ–è€…æŸ¥çœ‹[æˆ‘çš„ä¸ªäººé¡µé¢](http://markmansur.me/)ã€‚